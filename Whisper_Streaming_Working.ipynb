{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNti6u/PgTwPe4NywHLpTjy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acrching/WhisperLive/blob/main/Whisper_Streaming_Working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faster-whisper\n",
        "!pip install streamlink\n",
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "id": "M2zuJbAMdHVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFY1uV4OdFmM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import queue\n",
        "import threading\n",
        "import ffmpeg\n",
        "import streamlink\n",
        "from faster_whisper import WhisperModel\n",
        "\n",
        "AUDIO_BUFFER_SIZE = 30  # Buffer size in seconds\n",
        "\n",
        "class WhisperOnline:\n",
        "    def __init__(self, model_size, hls_url, device=\"cuda\", compute_type=\"float16\"):\n",
        "        self.audio_buffer = queue.Queue(maxsize=AUDIO_BUFFER_SIZE * 16000)\n",
        "        self.model = WhisperModel(model_size, device=device, compute_type=compute_type)\n",
        "        self.hls_url = hls_url\n",
        "        self.partial_transcription = \"\"\n",
        "\n",
        "    def download_audio(self):\n",
        "        streams = streamlink.streams(self.hls_url)\n",
        "        stream_url = streams['best'].url\n",
        "\n",
        "        process = (\n",
        "            ffmpeg\n",
        "            .input(stream_url)\n",
        "            .output('pipe:', format='wav', acodec='pcm_s16le', ac=1, ar='16k')\n",
        "            .run_async(pipe_stdout=True, pipe_stderr=True)\n",
        "        )\n",
        "        while True:\n",
        "            in_bytes = process.stdout.read(1024)\n",
        "            if not in_bytes:\n",
        "                break\n",
        "            self.audio_buffer.put(np.frombuffer(in_bytes, np.int16).astype(np.float32) / 32768.0)\n",
        "\n",
        "    def transcribe_audio(self):\n",
        "        while True:\n",
        "            if not self.audio_buffer.empty():\n",
        "                audio_chunk = []\n",
        "                for _ in range(16000 * 10):\n",
        "                    if not self.audio_buffer.empty():\n",
        "                        audio_chunk.append(self.audio_buffer.get())\n",
        "                    else:\n",
        "                        break\n",
        "                if len(audio_chunk) == 0:\n",
        "                    break\n",
        "                audio_chunk = np.concatenate(audio_chunk)\n",
        "                segments, _ = self.model.transcribe(audio_chunk)\n",
        "\n",
        "                for segment in segments:\n",
        "                    self.partial_transcription += segment.text\n",
        "                    if segment.text.endswith(('.', '!', '?')):\n",
        "                        print(self.partial_transcription.strip())\n",
        "                        self.partial_transcription = \"\"\n",
        "\n",
        "    def run(self):\n",
        "        download_thread = threading.Thread(target=self.download_audio)\n",
        "        transcribe_thread = threading.Thread(target=self.transcribe_audio)\n",
        "\n",
        "        download_thread.start()\n",
        "        transcribe_thread.start()\n",
        "\n",
        "        download_thread.join()\n",
        "        transcribe_thread.join()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_size = 'large-v2'  # Model size for faster-whisper\n",
        "    hls_url = 'https://dcs-live-uc1.mp.lura.live/server/play/5Awwm3GfagVzfpdA/rendition.m3u8?track=video-0&anvsid=m177626920-ndab3eff76c62376fec5de9c0c5b1b864&ts=1722924916&anvtrid=ba41b16c22763280dc45544f34528be9'  # Replace with your HLS stream URL\n",
        "\n",
        "    whisper_online = WhisperOnline(model_size, hls_url, device=\"cuda\", compute_type=\"float16\")\n",
        "    whisper_online.run()"
      ]
    }
  ]
}